{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean NCES schools\n",
    "\n",
    "Transforms historic lists of schools downloaded from federal database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cleaning up address columns. Works for all federal and local school files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace = [\n",
    "    ['W.', 'West'],\n",
    "    ['E.', 'East'],\n",
    "    ['S.', 'South'],\n",
    "    ['N.', 'North'],\n",
    "    ['Pkwy', 'Parkway'],\n",
    "    ['Place', 'Pl'],\n",
    "    ['Pla', 'Pl'],\n",
    "    ['Avenue', 'Ave'],\n",
    "    ['Broadway', 'BrdWay'],\n",
    "    ['  ',' '],\n",
    "    [',',''],\n",
    "    ['.','']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_addy(street):\n",
    "    \"\"\"\n",
    "    Submit a dirty address and get a clean one back.\n",
    "    \"\"\"\n",
    "    for key, value in replace:\n",
    "        street = street.replace(key, value)\n",
    "    return street"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to clean up school files. First a generic one for most files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(filename, filetype):\n",
    "    \"\"\"\n",
    "    Reads in file for each year and creates school code column\n",
    "    \"\"\"\n",
    "    #Read in differently depending on file type\n",
    "    path = os.path.join(input_dir, filename)\n",
    "    if filetype == 'csv':\n",
    "        df = pd.read_csv(path, encoding=\"latin-1\")\n",
    "    elif filetype == 'txt':\n",
    "        df = pd.read_csv(path, delimiter='\\t', encoding=\"latin-1\")\n",
    "    \n",
    "    #Filter out to California\n",
    "    cal_df = df[df.STATENAME == 'CALIFORNIA']\n",
    "    \n",
    "    #Filter out to LA county  \n",
    "    cal_df['county'] = cal_df.ST_LEAID.apply(lambda x: str(x)[-7:-5])\n",
    "    cal_df = cal_df[cal_df.county == '19']\n",
    "    \n",
    "    #Create column for school code. Adds leading zero where necessary.\n",
    "    cal_df['school_code'] = cal_df['ST_SCHID'].apply(lambda x: x[-7:] if type(x)==str else str('{:07d}'.format(x)))\n",
    "    \n",
    "    #Trim to three columns \n",
    "    cal_df_trim = cal_df[['school_code', 'LSTREET1', 'LCITY']]\n",
    "    \n",
    "    #Pretty columns\n",
    "    cal_df_trim.rename(columns={\n",
    "        'LSTREET1': 'street',\n",
    "        'LCITY': 'city',\n",
    "    }, inplace=True)\n",
    "    \n",
    "    #Everything to title case for matching later\n",
    "    cal_df_clean = cal_df_trim.apply(lambda x: x.astype(str).str.title()) \n",
    "    \n",
    "    #Cleaning up street column for matching later\n",
    "    cal_df_clean['street'] = cal_df_clean['street'].apply(clean_addy)\n",
    "        \n",
    "    return cal_df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a special one for the oddball file from 2013-14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_1314(filename):\n",
    "    \"\"\"\n",
    "    Transforms 2013-2014 file from NCES\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(os.path.join(input_dir, filename), delimiter='\\t')\n",
    "    \n",
    "    #Filter to CA\n",
    "    df = df[df.FIPST == 6] \n",
    "    \n",
    "    #Filter to LA county\n",
    "    df['county'] = df.STID.apply(lambda x: str(x)[-7:-5])\n",
    "    df = df[df.county == '19']\n",
    "    \n",
    "    df.rename(columns={\n",
    "        'SEASCH':'school_code',\n",
    "        'LSTREE':'street', \n",
    "        'LCITY':'city',\n",
    "    }, inplace=True)\n",
    "    df = df[['school_code','street','city']]\n",
    "\n",
    "    df['school_code'] = df['school_code'].apply(lambda x: str('{:07d}'.format(x)))\n",
    "    \n",
    "    df_new = df.apply(lambda x: x.astype(str).str.title()) \n",
    "    \n",
    "    df_new['street'] = df_new['street'].apply(clean_addy)\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform national files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1314 = transform_1314('sc132a.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1415  = transform('ccd_sch_029_1415_w_0216601a.txt', 'txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1516  = transform('ccd_sch_029_1516_w_2a_011717.csv', 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1617  = transform('ccd_sch_029_1617_w_1a_11212017.csv', 'csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_df = lambda df, year: df.to_csv(os.path.join(output_dir, \"df_{}.csv\".format(year)), index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_df(df1314, \"1314\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_df(df1415, \"1415\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_df(df1516, \"1516\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_df(df1617, \"1617\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
